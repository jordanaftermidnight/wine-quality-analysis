{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QcGvis1LPCiY",
        "outputId": "275730b4-99ea-44d5-f9bc-c5f470aa7f44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version: 3.11.13\n",
            "Numpy version: 2.0.2\n",
            "Pandas version: 2.2.2\n",
            "Scikit-learn version: 1.6.1\n",
            "Plotly version: 5.24.1\n",
            "IPython version: 7.34.0\n",
            "================================================================================\n",
            "LOADING AND EXPLORING THE WINE QUALITY DATASET\n",
            "================================================================================\n",
            "Successfully loaded the dataset from https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\n",
            "\n",
            "Dataset shape: (1599, 12) (rows, columns)\n",
            "\n",
            "First 5 rows:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
              "0            7.4              0.70         0.00             1.9      0.076   \n",
              "1            7.8              0.88         0.00             2.6      0.098   \n",
              "2            7.8              0.76         0.04             2.3      0.092   \n",
              "3           11.2              0.28         0.56             1.9      0.075   \n",
              "4            7.4              0.70         0.00             1.9      0.076   \n",
              "\n",
              "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
              "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
              "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
              "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
              "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
              "\n",
              "   alcohol  quality  \n",
              "0      9.4        5  \n",
              "1      9.8        5  \n",
              "2      9.8        5  \n",
              "3      9.8        6  \n",
              "4      9.4        5  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a62a5da3-ef8a-4d2a-a50f-e8a962b04fd9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.88</td>\n",
              "      <td>0.00</td>\n",
              "      <td>2.6</td>\n",
              "      <td>0.098</td>\n",
              "      <td>25.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>0.9968</td>\n",
              "      <td>3.20</td>\n",
              "      <td>0.68</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.8</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.04</td>\n",
              "      <td>2.3</td>\n",
              "      <td>0.092</td>\n",
              "      <td>15.0</td>\n",
              "      <td>54.0</td>\n",
              "      <td>0.9970</td>\n",
              "      <td>3.26</td>\n",
              "      <td>0.65</td>\n",
              "      <td>9.8</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.2</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.075</td>\n",
              "      <td>17.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>0.9980</td>\n",
              "      <td>3.16</td>\n",
              "      <td>0.58</td>\n",
              "      <td>9.8</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.4</td>\n",
              "      <td>0.70</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.9</td>\n",
              "      <td>0.076</td>\n",
              "      <td>11.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.9978</td>\n",
              "      <td>3.51</td>\n",
              "      <td>0.56</td>\n",
              "      <td>9.4</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a62a5da3-ef8a-4d2a-a50f-e8a962b04fd9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a62a5da3-ef8a-4d2a-a50f-e8a962b04fd9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a62a5da3-ef8a-4d2a-a50f-e8a962b04fd9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-a50eac3a-9a48-4a1d-8773-119ede46d861\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a50eac3a-9a48-4a1d-8773-119ede46d861')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-a50eac3a-9a48-4a1d-8773-119ede46d861 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"\\\"\\\"\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"fixed acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.6223439832538593,\n        \"min\": 7.4,\n        \"max\": 11.2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          7.4,\n          7.8,\n          11.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatile acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.22689204481426842,\n        \"min\": 0.28,\n        \"max\": 0.88,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.88,\n          0.28,\n          0.7\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"citric acid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.24657656011875909,\n        \"min\": 0.0,\n        \"max\": 0.56,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.0,\n          0.04,\n          0.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"residual sugar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.31937438845342636,\n        \"min\": 1.9,\n        \"max\": 2.6,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          1.9,\n          2.6,\n          2.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chlorides\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.010807404868885038,\n        \"min\": 0.075,\n        \"max\": 0.098,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.098,\n          0.075,\n          0.076\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"free sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 5.761944116355173,\n        \"min\": 11.0,\n        \"max\": 25.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          25.0,\n          17.0,\n          11.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15.139352694220449,\n        \"min\": 34.0,\n        \"max\": 67.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          67.0,\n          60.0,\n          34.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0005403702434442519,\n        \"min\": 0.9968,\n        \"max\": 0.998,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.9968,\n          0.998,\n          0.9978\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.16991174179555674,\n        \"min\": 3.16,\n        \"max\": 3.51,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3.2,\n          3.16,\n          3.51\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sulphates\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05549774770204643,\n        \"min\": 0.56,\n        \"max\": 0.68,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          0.68,\n          0.58,\n          0.56\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alcohol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21908902300206665,\n        \"min\": 9.4,\n        \"max\": 9.8,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          9.8,\n          9.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 5,\n        \"max\": 6,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          6,\n          5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Summary statistics:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
              "count    1599.000000       1599.000000  1599.000000     1599.000000   \n",
              "mean        8.319637          0.527821     0.270976        2.538806   \n",
              "std         1.741096          0.179060     0.194801        1.409928   \n",
              "min         4.600000          0.120000     0.000000        0.900000   \n",
              "25%         7.100000          0.390000     0.090000        1.900000   \n",
              "50%         7.900000          0.520000     0.260000        2.200000   \n",
              "75%         9.200000          0.640000     0.420000        2.600000   \n",
              "max        15.900000          1.580000     1.000000       15.500000   \n",
              "\n",
              "         chlorides  free sulfur dioxide  total sulfur dioxide      density  \\\n",
              "count  1599.000000          1599.000000           1599.000000  1599.000000   \n",
              "mean      0.087467            15.874922             46.467792     0.996747   \n",
              "std       0.047065            10.460157             32.895324     0.001887   \n",
              "min       0.012000             1.000000              6.000000     0.990070   \n",
              "25%       0.070000             7.000000             22.000000     0.995600   \n",
              "50%       0.079000            14.000000             38.000000     0.996750   \n",
              "75%       0.090000            21.000000             62.000000     0.997835   \n",
              "max       0.611000            72.000000            289.000000     1.003690   \n",
              "\n",
              "                pH    sulphates      alcohol      quality  \n",
              "count  1599.000000  1599.000000  1599.000000  1599.000000  \n",
              "mean      3.311113     0.658149    10.422983     5.636023  \n",
              "std       0.154386     0.169507     1.065668     0.807569  \n",
              "min       2.740000     0.330000     8.400000     3.000000  \n",
              "25%       3.210000     0.550000     9.500000     5.000000  \n",
              "50%       3.310000     0.620000    10.200000     6.000000  \n",
              "75%       3.400000     0.730000    11.100000     6.000000  \n",
              "max       4.010000     2.000000    14.900000     8.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4acd429b-4cf4-49f9-9f40-2add7a6d1e3b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fixed acidity</th>\n",
              "      <th>volatile acidity</th>\n",
              "      <th>citric acid</th>\n",
              "      <th>residual sugar</th>\n",
              "      <th>chlorides</th>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <th>density</th>\n",
              "      <th>pH</th>\n",
              "      <th>sulphates</th>\n",
              "      <th>alcohol</th>\n",
              "      <th>quality</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "      <td>1599.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>8.319637</td>\n",
              "      <td>0.527821</td>\n",
              "      <td>0.270976</td>\n",
              "      <td>2.538806</td>\n",
              "      <td>0.087467</td>\n",
              "      <td>15.874922</td>\n",
              "      <td>46.467792</td>\n",
              "      <td>0.996747</td>\n",
              "      <td>3.311113</td>\n",
              "      <td>0.658149</td>\n",
              "      <td>10.422983</td>\n",
              "      <td>5.636023</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.741096</td>\n",
              "      <td>0.179060</td>\n",
              "      <td>0.194801</td>\n",
              "      <td>1.409928</td>\n",
              "      <td>0.047065</td>\n",
              "      <td>10.460157</td>\n",
              "      <td>32.895324</td>\n",
              "      <td>0.001887</td>\n",
              "      <td>0.154386</td>\n",
              "      <td>0.169507</td>\n",
              "      <td>1.065668</td>\n",
              "      <td>0.807569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>4.600000</td>\n",
              "      <td>0.120000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.012000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>0.990070</td>\n",
              "      <td>2.740000</td>\n",
              "      <td>0.330000</td>\n",
              "      <td>8.400000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>7.100000</td>\n",
              "      <td>0.390000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>1.900000</td>\n",
              "      <td>0.070000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>0.995600</td>\n",
              "      <td>3.210000</td>\n",
              "      <td>0.550000</td>\n",
              "      <td>9.500000</td>\n",
              "      <td>5.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.900000</td>\n",
              "      <td>0.520000</td>\n",
              "      <td>0.260000</td>\n",
              "      <td>2.200000</td>\n",
              "      <td>0.079000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>38.000000</td>\n",
              "      <td>0.996750</td>\n",
              "      <td>3.310000</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>10.200000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>9.200000</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>0.420000</td>\n",
              "      <td>2.600000</td>\n",
              "      <td>0.090000</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>62.000000</td>\n",
              "      <td>0.997835</td>\n",
              "      <td>3.400000</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>11.100000</td>\n",
              "      <td>6.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>15.900000</td>\n",
              "      <td>1.580000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>15.500000</td>\n",
              "      <td>0.611000</td>\n",
              "      <td>72.000000</td>\n",
              "      <td>289.000000</td>\n",
              "      <td>1.003690</td>\n",
              "      <td>4.010000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.900000</td>\n",
              "      <td>8.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4acd429b-4cf4-49f9-9f40-2add7a6d1e3b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4acd429b-4cf4-49f9-9f40-2add7a6d1e3b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4acd429b-4cf4-49f9-9f40-2add7a6d1e3b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-6268a3e0-c37e-4d9b-8847-62495bf3b735\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6268a3e0-c37e-4d9b-8847-62495bf3b735')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-6268a3e0-c37e-4d9b-8847-62495bf3b735 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"\\\"\\\"\\\")\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"fixed acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 562.5806745048905,\n        \"min\": 1.7410963181277006,\n        \"max\": 1599.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          8.31963727329581,\n          7.9,\n          1599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"volatile acidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 565.1321980080039,\n        \"min\": 0.12,\n        \"max\": 1599.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.5278205128205128,\n          0.52,\n          1599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"citric acid\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 565.2190298438521,\n        \"min\": 0.0,\n        \"max\": 1599.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.2709756097560976,\n          0.26,\n          1599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"residual sugar\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 563.9859918397556,\n        \"min\": 0.9,\n        \"max\": 1599.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          2.53880550343965,\n          2.2,\n          1599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"chlorides\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 565.2815720420848,\n        \"min\": 0.012,\n        \"max\": 1599.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.08746654158849279,\n          0.079,\n          1599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"free sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 558.6255652064851,\n        \"min\": 1.0,\n        \"max\": 1599.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          15.874921826141339,\n          14.0,\n          1599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"total sulfur dioxide\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 547.7946740169228,\n        \"min\": 6.0,\n        \"max\": 1599.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          46.46779237023139,\n          38.0,\n          1599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"density\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 565.0298129526797,\n        \"min\": 0.0018873339538425559,\n        \"max\": 1599.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.9967466791744841,\n          0.99675,\n          1599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 564.3160746075233,\n        \"min\": 0.15438646490354266,\n        \"max\": 1599.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.3111131957473416,\n          3.31,\n          1599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sulphates\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 565.0766914059569,\n        \"min\": 0.16950697959010977,\n        \"max\": 1599.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.6581488430268917,\n          0.62,\n          1599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"alcohol\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 562.0325260314485,\n        \"min\": 1.0656675818473926,\n        \"max\": 1599.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          10.422983114446529,\n          10.2,\n          1599.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 563.5963817822504,\n        \"min\": 0.8075694397347023,\n        \"max\": 1599.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1599.0,\n          5.6360225140712945,\n          6.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Missing values per column:\n",
            "No missing values found!\n",
            "\n",
            "Data types:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "fixed acidity           float64\n",
              "volatile acidity        float64\n",
              "citric acid             float64\n",
              "residual sugar          float64\n",
              "chlorides               float64\n",
              "free sulfur dioxide     float64\n",
              "total sulfur dioxide    float64\n",
              "density                 float64\n",
              "pH                      float64\n",
              "sulphates               float64\n",
              "alcohol                 float64\n",
              "quality                   int64\n",
              "dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>fixed acidity</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volatile acidity</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>citric acid</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>residual sugar</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>chlorides</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>free sulfur dioxide</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>total sulfur dioxide</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>density</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pH</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sulphates</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>alcohol</th>\n",
              "      <td>float64</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>quality</th>\n",
              "      <td>int64</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "EXPLORATORY DATA ANALYSIS\n",
            "================================================================================\n",
            "================================================================================\n",
            "DATA PREPARATION\n",
            "================================================================================\n",
            "Class distribution (High Quality = 7+):\n",
            "Low Quality (0): 1382 samples (86.4%)\n",
            "High Quality (1): 217 samples (13.6%)\n",
            "\n",
            "Train set: 1279 samples\n",
            "Test set: 320 samples\n",
            "\n",
            "Scaled data statistics:\n",
            "Mean of scaled training features: [-1.11109106e-16  4.11798126e-16  1.26386609e-16]...\n",
            "Std of scaled training features: [1. 1. 1.]...\n",
            "================================================================================\n",
            "REGRESSION TASK: PREDICTING WINE QUALITY SCORE\n",
            "================================================================================\n",
            "Initial model comparison with 5-fold cross-validation:\n",
            "Evaluating regression models with 5-fold cross-validation...\n",
            "  Evaluating Linear Regression...\n",
            "  Evaluating Ridge...\n",
            "  Evaluating Lasso...\n",
            "  Evaluating ElasticNet...\n",
            "  Evaluating SVR...\n",
            "  Evaluating Random Forest...\n",
            "  Evaluating Gradient Boosting...\n"
          ]
        }
      ],
      "source": [
        "# Wine Quality Analysis: Regression and Classification\n",
        "# =======================================================\n",
        "#\n",
        "# This notebook demonstrates a comprehensive machine learning pipeline for\n",
        "# predicting wine quality using both regression and classification approaches.\n",
        "#\n",
        "# Author: [Your Name]\n",
        "# GitHub: https://github.com/yourusername\n",
        "\n",
        "# %%\n",
        "# --- Setup and Environment Checking ---\n",
        "import sys\n",
        "import platform\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import __version__ as sklearn_version\n",
        "import plotly\n",
        "import IPython\n",
        "\n",
        "# Display environment info for reproducibility\n",
        "print(f\"Python version: {platform.python_version()}\")\n",
        "print(f\"Numpy version: {np.__version__}\")\n",
        "print(f\"Pandas version: {pd.__version__}\")\n",
        "print(f\"Scikit-learn version: {sklearn_version}\")\n",
        "print(f\"Plotly version: {plotly.__version__}\")\n",
        "print(f\"IPython version: {IPython.__version__}\")\n",
        "\n",
        "# Set random seed for reproducibility across the entire notebook\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "\n",
        "# Standard imports for the project\n",
        "from sklearn.model_selection import train_test_split, KFold, GridSearchCV, RandomizedSearchCV, cross_val_score, learning_curve\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
        "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, roc_auc_score, roc_curve\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.base import clone\n",
        "from sklearn.manifold import TSNE\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Setup matplotlib and seaborn for consistent styling\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette(\"deep\")\n",
        "plt.rcParams['figure.figsize'] = (12, 8)\n",
        "plt.rcParams['figure.dpi'] = 100\n",
        "\n",
        "# Function to save figures for GitHub README\n",
        "def save_fig(fig, filename, folder=\"images/\", dpi=300, bbox_inches=\"tight\"):\n",
        "    \"\"\"Save figure for GitHub documentation\"\"\"\n",
        "    import os\n",
        "    if not os.path.exists(folder):\n",
        "        os.makedirs(folder)\n",
        "    fig.savefig(f\"{folder}{filename}\", dpi=dpi, bbox_inches=bbox_inches)\n",
        "    plt.close(fig)\n",
        "\n",
        "# %%\n",
        "# --- Data Loading and Initial Exploration ---\n",
        "print(\"=\" * 80)\n",
        "print(\"LOADING AND EXPLORING THE WINE QUALITY DATASET\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Load the dataset - we're using the red wine quality dataset from UCI\n",
        "try:\n",
        "    url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv'\n",
        "    wine_data = pd.read_csv(url, sep=';')\n",
        "    print(f\"Successfully loaded the dataset from {url}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading dataset from URL: {e}\")\n",
        "    print(\"Trying to load from local file...\")\n",
        "    try:\n",
        "        wine_data = pd.read_csv(\"data/winequality-red.csv\", sep=';')\n",
        "        print(\"Successfully loaded the dataset from local file\")\n",
        "    except:\n",
        "        print(\"Failed to load dataset. Please download it manually from:\")\n",
        "        print(\"https://archive.ics.uci.edu/ml/datasets/wine+quality\")\n",
        "        # Exit or continue with sample data...\n",
        "        raise\n",
        "\n",
        "# Display basic information about the dataset\n",
        "print(f\"\\nDataset shape: {wine_data.shape} (rows, columns)\")\n",
        "print(\"\\nFirst 5 rows:\")\n",
        "display(wine_data.head())\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nSummary statistics:\")\n",
        "display(wine_data.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "missing_data = wine_data.isnull().sum()\n",
        "if missing_data.sum() > 0:\n",
        "    print(missing_data[missing_data > 0])\n",
        "else:\n",
        "    print(\"No missing values found!\")\n",
        "\n",
        "# Data types\n",
        "print(\"\\nData types:\")\n",
        "display(wine_data.dtypes)\n",
        "\n",
        "# %%\n",
        "# --- Exploratory Data Analysis with Static Visualizations for GitHub ---\n",
        "print(\"=\" * 80)\n",
        "print(\"EXPLORATORY DATA ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Distribution of the quality scores\n",
        "plt.figure(figsize=(10, 6))\n",
        "ax = sns.countplot(x='quality', data=wine_data, palette='viridis')\n",
        "plt.title('Distribution of Wine Quality Scores', fontsize=16)\n",
        "plt.xlabel('Quality Score', fontsize=14)\n",
        "plt.ylabel('Count', fontsize=14)\n",
        "\n",
        "# Add count labels on top of each bar\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height()}',\n",
        "                (p.get_x() + p.get_width() / 2., p.get_height()),\n",
        "                ha = 'center', va = 'bottom',\n",
        "                fontsize=12)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"quality_distribution.png\")\n",
        "plt.show()\n",
        "\n",
        "# Plot the correlation matrix\n",
        "plt.figure(figsize=(12, 10))\n",
        "corr_matrix = wine_data.corr()\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
        "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
        "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt='.2f', cmap=cmap, square=True)\n",
        "plt.title('Correlation Matrix of Wine Features', fontsize=16)\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"correlation_matrix.png\")\n",
        "plt.show()\n",
        "\n",
        "# Distribution of features\n",
        "fig, axes = plt.subplots(4, 3, figsize=(18, 16))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(wine_data.columns):\n",
        "    if i < len(axes):\n",
        "        sns.histplot(wine_data[col], kde=True, ax=axes[i], color='skyblue')\n",
        "        axes[i].set_title(f'Distribution of {col}', fontsize=12)\n",
        "        axes[i].tick_params(labelsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"feature_distributions.png\")\n",
        "plt.show()\n",
        "\n",
        "# Create pairplots for key features\n",
        "important_features = ['alcohol', 'volatile acidity', 'sulphates', 'pH', 'quality']\n",
        "pair_plot = sns.pairplot(wine_data[important_features], hue='quality', palette='viridis',\n",
        "                          plot_kws={'alpha': 0.6})\n",
        "plt.suptitle('Pairplot of Key Wine Features', y=1.02, fontsize=16)\n",
        "save_fig(pair_plot.fig, \"feature_pairplot.png\")\n",
        "plt.show()\n",
        "\n",
        "# Feature relationships with quality\n",
        "fig, axes = plt.subplots(3, 4, figsize=(20, 15))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, col in enumerate(wine_data.columns[:-1]):  # Exclude quality\n",
        "    if i < len(axes):\n",
        "        sns.boxplot(x='quality', y=col, data=wine_data, ax=axes[i], palette='viridis')\n",
        "        axes[i].set_title(f'{col} by Quality', fontsize=12)\n",
        "        axes[i].tick_params(labelsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"features_by_quality.png\")\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# --- Data Preparation ---\n",
        "print(\"=\" * 80)\n",
        "print(\"DATA PREPARATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Feature matrix and target variable for regression\n",
        "X = wine_data.drop('quality', axis=1)\n",
        "y_reg = wine_data['quality']\n",
        "\n",
        "# For classification, we'll define 'high quality' as wines with quality >= 7\n",
        "quality_threshold = 7\n",
        "y_cls = (y_reg >= quality_threshold).astype(int)\n",
        "print(f\"Class distribution (High Quality = {quality_threshold}+):\")\n",
        "print(f\"Low Quality (0): {sum(y_cls == 0)} samples ({sum(y_cls == 0)/len(y_cls):.1%})\")\n",
        "print(f\"High Quality (1): {sum(y_cls == 1)} samples ({sum(y_cls == 1)/len(y_cls):.1%})\")\n",
        "\n",
        "# Visualize class distribution\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(y_cls.value_counts(), labels=['Low Quality', 'High Quality'],\n",
        "        autopct='%1.1f%%', colors=['#ff7f0e', '#2ca02c'],\n",
        "        explode=[0, 0.1], shadow=True)\n",
        "plt.title('Class Distribution for Wine Quality Classification', fontsize=16)\n",
        "save_fig(plt.gcf(), \"class_distribution.png\")\n",
        "plt.show()\n",
        "\n",
        "# Split the data into training and testing sets (common for both tasks)\n",
        "X_train, X_test, y_reg_train, y_reg_test, y_cls_train, y_cls_test = train_test_split(\n",
        "    X, y_reg, y_cls, test_size=0.2, random_state=RANDOM_SEED\n",
        ")\n",
        "\n",
        "print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "X_scaled = scaler.transform(X)  # Full dataset for later visualizations\n",
        "\n",
        "# Verify scaling worked correctly\n",
        "print(\"\\nScaled data statistics:\")\n",
        "print(f\"Mean of scaled training features: {np.mean(X_train_scaled, axis=0)[:3]}...\")\n",
        "print(f\"Std of scaled training features: {np.std(X_train_scaled, axis=0)[:3]}...\")\n",
        "\n",
        "# %%\n",
        "# --- Regression Task: Initial Model Comparison ---\n",
        "print(\"=\" * 80)\n",
        "print(\"REGRESSION TASK: PREDICTING WINE QUALITY SCORE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Define regression models to test\n",
        "regression_models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Ridge': Ridge(random_state=RANDOM_SEED),\n",
        "    'Lasso': Lasso(random_state=RANDOM_SEED),\n",
        "    'ElasticNet': ElasticNet(random_state=RANDOM_SEED),\n",
        "    'SVR': SVR(),\n",
        "    'Random Forest': RandomForestRegressor(random_state=RANDOM_SEED),\n",
        "    'Gradient Boosting': GradientBoostingRegressor(random_state=RANDOM_SEED),\n",
        "    'KNN': KNeighborsRegressor()\n",
        "}\n",
        "\n",
        "# Function to evaluate models with cross-validation\n",
        "def evaluate_regression_models(models, X, y, cv=5):\n",
        "    print(f\"Evaluating regression models with {cv}-fold cross-validation...\")\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        print(f\"  Evaluating {name}...\")\n",
        "        rmse_scores = np.sqrt(-cross_val_score(model, X, y,\n",
        "                                              scoring='neg_mean_squared_error',\n",
        "                                              cv=cv))\n",
        "        r2_scores = cross_val_score(model, X, y, scoring='r2', cv=cv)\n",
        "        mae_scores = -cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv)\n",
        "\n",
        "        results[name] = {\n",
        "            'RMSE': rmse_scores.mean(),\n",
        "            'RMSE_std': rmse_scores.std(),\n",
        "            'R2': r2_scores.mean(),\n",
        "            'R2_std': r2_scores.std(),\n",
        "            'MAE': mae_scores.mean(),\n",
        "            'MAE_std': mae_scores.std()\n",
        "        }\n",
        "    return results\n",
        "\n",
        "# Evaluate all models\n",
        "print(\"Initial model comparison with 5-fold cross-validation:\")\n",
        "regression_results = evaluate_regression_models(regression_models, X_train_scaled, y_reg_train)\n",
        "results_df = pd.DataFrame(regression_results).T\n",
        "results_df = results_df.sort_values('RMSE')\n",
        "display(results_df)\n",
        "\n",
        "# Plot the performance comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# RMSE Plot\n",
        "results_df['RMSE'].plot(kind='bar', yerr=results_df['RMSE_std'], color='skyblue', ax=axes[0])\n",
        "axes[0].set_title('RMSE Comparison (Lower is Better)', fontsize=14)\n",
        "axes[0].set_ylabel('RMSE', fontsize=12)\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# R Plot\n",
        "results_df['R2'].plot(kind='bar', yerr=results_df['R2_std'], color='lightgreen', ax=axes[1])\n",
        "axes[1].set_title('R Comparison (Higher is Better)', fontsize=14)\n",
        "axes[1].set_ylabel('R', fontsize=12)\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# MAE Plot\n",
        "results_df['MAE'].plot(kind='bar', yerr=results_df['MAE_std'], color='salmon', ax=axes[2])\n",
        "axes[2].set_title('MAE Comparison (Lower is Better)', fontsize=14)\n",
        "axes[2].set_ylabel('MAE', fontsize=12)\n",
        "axes[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"regression_model_comparison.png\")\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# --- Regression Task: Hyperparameter Tuning ---\n",
        "print(\"=\" * 80)\n",
        "print(\"REGRESSION TASK: HYPERPARAMETER TUNING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Based on initial results, tune the top 2 performing models\n",
        "# (Assuming Random Forest and Gradient Boosting performed best from the previous comparison)\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import time\n",
        "\n",
        "# 2.1 Random Forest Tuning\n",
        "print(\"\\nTuning Random Forest Regressor parameters:\")\n",
        "rf_param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "rf_regressor = RandomForestRegressor(random_state=RANDOM_SEED)\n",
        "\n",
        "# Track time for tuning\n",
        "start_time = time.time()\n",
        "rf_grid_search = GridSearchCV(\n",
        "    estimator=rf_regressor,\n",
        "    param_grid=rf_param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rf_grid_search.fit(X_train_scaled, y_reg_train)\n",
        "rf_tuning_time = time.time() - start_time\n",
        "\n",
        "print(f\"Tuning completed in {rf_tuning_time:.2f} seconds\")\n",
        "print(f\"Best parameters: {rf_grid_search.best_params_}\")\n",
        "print(f\"Best RMSE: {np.sqrt(-rf_grid_search.best_score_):.4f}\")\n",
        "\n",
        "# 2.2 Gradient Boosting Tuning\n",
        "print(\"\\nTuning Gradient Boosting Regressor parameters:\")\n",
        "gb_param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'subsample': [0.8, 0.9, 1.0]\n",
        "}\n",
        "\n",
        "gb_regressor = GradientBoostingRegressor(random_state=RANDOM_SEED)\n",
        "\n",
        "# Track time for tuning\n",
        "start_time = time.time()\n",
        "gb_grid_search = GridSearchCV(\n",
        "    estimator=gb_regressor,\n",
        "    param_grid=gb_param_grid,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "gb_grid_search.fit(X_train_scaled, y_reg_train)\n",
        "gb_tuning_time = time.time() - start_time\n",
        "\n",
        "print(f\"Tuning completed in {gb_tuning_time:.2f} seconds\")\n",
        "print(f\"Best parameters: {gb_grid_search.best_params_}\")\n",
        "print(f\"Best RMSE: {np.sqrt(-gb_grid_search.best_score_):.4f}\")\n",
        "\n",
        "# Select the best model based on cross-validation results\n",
        "rf_rmse = np.sqrt(-rf_grid_search.best_score_)\n",
        "gb_rmse = np.sqrt(-gb_grid_search.best_score_)\n",
        "\n",
        "if rf_rmse < gb_rmse:\n",
        "    best_reg_model = rf_grid_search.best_estimator_\n",
        "    best_reg_params = rf_grid_search.best_params_\n",
        "    best_reg_model_name = \"Random Forest\"\n",
        "    reg_grid_results = rf_grid_search.cv_results_\n",
        "else:\n",
        "    best_reg_model = gb_grid_search.best_estimator_\n",
        "    best_reg_params = gb_grid_search.best_params_\n",
        "    best_reg_model_name = \"Gradient Boosting\"\n",
        "    reg_grid_results = gb_grid_search.cv_results_\n",
        "\n",
        "print(f\"\\nBest regression model: {best_reg_model_name}\")\n",
        "print(f\"Best parameters: {best_reg_params}\")\n",
        "\n",
        "# Visualize top parameter combinations\n",
        "# Extract the CV results from grid search\n",
        "rmse_scores = np.sqrt(-reg_grid_results['mean_test_score'])\n",
        "param_combinations = [str(p) for p in reg_grid_results['params']]\n",
        "\n",
        "# Plot the top 15 parameter combinations\n",
        "top_indices = np.argsort(rmse_scores)[:15]\n",
        "top_rmse = rmse_scores[top_indices]\n",
        "top_params = [param_combinations[i] for i in top_indices]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(top_rmse)), top_rmse, color='skyblue')\n",
        "plt.yticks(range(len(top_rmse)), [f\"Config {i+1}\" for i in range(len(top_rmse))])\n",
        "plt.xlabel('RMSE (Lower is Better)')\n",
        "plt.title(f'Top 15 Parameter Combinations for {best_reg_model_name}')\n",
        "\n",
        "# Add parameter details as text\n",
        "for i, (rmse, params) in enumerate(zip(top_rmse, top_params)):\n",
        "    plt.text(rmse + 0.01, i, f\"{rmse:.4f}\", va='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"regression_top_params.png\")\n",
        "plt.show()\n",
        "\n",
        "# Display the actual parameter configurations\n",
        "top_params_df = pd.DataFrame([reg_grid_results['params'][i] for i in top_indices])\n",
        "top_params_df['RMSE'] = top_rmse\n",
        "display(top_params_df)\n",
        "\n",
        "# %%\n",
        "# --- Classification Task: Initial Model Comparison ---\n",
        "print(\"=\" * 80)\n",
        "print(\"CLASSIFICATION TASK: PREDICTING HIGH QUALITY WINE\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Define classification models to test\n",
        "classification_models = {\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000, random_state=RANDOM_SEED),\n",
        "    'Random Forest': RandomForestClassifier(random_state=RANDOM_SEED),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(random_state=RANDOM_SEED),\n",
        "    'SVC': SVC(probability=True, random_state=RANDOM_SEED),\n",
        "    'KNN': KNeighborsClassifier()\n",
        "}\n",
        "\n",
        "# Function to evaluate classification models with cross-validation\n",
        "def evaluate_classification_models(models, X, y, cv=5):\n",
        "    print(f\"Evaluating classification models with {cv}-fold cross-validation...\")\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        print(f\"  Evaluating {name}...\")\n",
        "        accuracy_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv)\n",
        "        f1_scores = cross_val_score(model, X, y, scoring='f1', cv=cv)\n",
        "        roc_auc_scores = cross_val_score(model, X, y, scoring='roc_auc', cv=cv)\n",
        "        precision_scores = cross_val_score(model, X, y, scoring='precision', cv=cv)\n",
        "        recall_scores = cross_val_score(model, X, y, scoring='recall', cv=cv)\n",
        "\n",
        "        results[name] = {\n",
        "            'Accuracy': accuracy_scores.mean(),\n",
        "            'Accuracy_std': accuracy_scores.std(),\n",
        "            'F1': f1_scores.mean(),\n",
        "            'F1_std': f1_scores.std(),\n",
        "            'ROC_AUC': roc_auc_scores.mean(),\n",
        "            'ROC_AUC_std': roc_auc_scores.std(),\n",
        "            'Precision': precision_scores.mean(),\n",
        "            'Precision_std': precision_scores.std(),\n",
        "            'Recall': recall_scores.mean(),\n",
        "            'Recall_std': recall_scores.std()\n",
        "        }\n",
        "    return results\n",
        "\n",
        "# Evaluate all models\n",
        "print(\"Initial model comparison with 5-fold cross-validation:\")\n",
        "classification_results = evaluate_classification_models(classification_models, X_train_scaled, y_cls_train)\n",
        "cls_results_df = pd.DataFrame(classification_results).T\n",
        "cls_results_df = cls_results_df.sort_values('F1', ascending=False)\n",
        "display(cls_results_df)\n",
        "\n",
        "# Plot the performance comparison\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "# Accuracy Plot\n",
        "cls_results_df['Accuracy'].plot(kind='bar', yerr=cls_results_df['Accuracy_std'], color='skyblue', ax=axes[0])\n",
        "axes[0].set_title('Accuracy Comparison', fontsize=14)\n",
        "axes[0].set_ylabel('Accuracy', fontsize=12)\n",
        "axes[0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# F1 Plot\n",
        "cls_results_df['F1'].plot(kind='bar', yerr=cls_results_df['F1_std'], color='lightgreen', ax=axes[1])\n",
        "axes[1].set_title('F1 Score Comparison', fontsize=14)\n",
        "axes[1].set_ylabel('F1 Score', fontsize=12)\n",
        "axes[1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# ROC AUC Plot\n",
        "cls_results_df['ROC_AUC'].plot(kind='bar', yerr=cls_results_df['ROC_AUC_std'], color='salmon', ax=axes[2])\n",
        "axes[2].set_title('ROC AUC Comparison', fontsize=14)\n",
        "axes[2].set_ylabel('ROC AUC', fontsize=12)\n",
        "axes[2].tick_params(axis='x', rotation=45)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"classification_model_comparison.png\")\n",
        "plt.show()\n",
        "\n",
        "# Radar chart for model comparison\n",
        "categories = ['Accuracy', 'F1', 'ROC_AUC', 'Precision', 'Recall']\n",
        "fig = plt.figure(figsize=(10, 8))\n",
        "\n",
        "# Calculate angles for radar chart\n",
        "angles = np.linspace(0, 2*np.pi, len(categories), endpoint=False).tolist()\n",
        "angles += angles[:1]  # Close the polygon\n",
        "\n",
        "ax = fig.add_subplot(111, polar=True)\n",
        "\n",
        "for model in cls_results_df.index:\n",
        "    values = cls_results_df.loc[model, categories].values.tolist()\n",
        "    values += values[:1]  # Close the polygon\n",
        "    ax.plot(angles, values, linewidth=2, label=model)\n",
        "    ax.fill(angles, values, alpha=0.1)\n",
        "\n",
        "ax.set_thetagrids(np.degrees(angles[:-1]), categories)\n",
        "ax.set_ylim(0.5, 1)\n",
        "ax.set_title('Classification Model Performance Comparison', fontsize=16)\n",
        "ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
        "\n",
        "save_fig(plt.gcf(), \"classification_radar_comparison.png\")\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# --- Classification Task: Hyperparameter Tuning ---\n",
        "print(\"=\" * 80)\n",
        "print(\"CLASSIFICATION TASK: HYPERPARAMETER TUNING\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# 2.1 Random Forest Tuning\n",
        "print(\"\\nTuning Random Forest Classifier parameters:\")\n",
        "rf_cls_param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'max_features': ['auto', 'sqrt', 'log2'],\n",
        "    'class_weight': [None, 'balanced', 'balanced_subsample']\n",
        "}\n",
        "\n",
        "rf_classifier = RandomForestClassifier(random_state=RANDOM_SEED)\n",
        "\n",
        "# Track time for tuning\n",
        "start_time = time.time()\n",
        "rf_cls_grid_search = GridSearchCV(\n",
        "    estimator=rf_classifier,\n",
        "    param_grid=rf_cls_param_grid,\n",
        "    scoring='f1',  # Optimize for F1 score due to class imbalance\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "rf_cls_grid_search.fit(X_train_scaled, y_cls_train)\n",
        "rf_cls_tuning_time = time.time() - start_time\n",
        "\n",
        "print(f\"Tuning completed in {rf_cls_tuning_time:.2f} seconds\")\n",
        "print(f\"Best parameters: {rf_cls_grid_search.best_params_}\")\n",
        "print(f\"Best F1 Score: {rf_cls_grid_search.best_score_:.4f}\")\n",
        "\n",
        "# 2.2 Gradient Boosting Tuning\n",
        "print(\"\\nTuning Gradient Boosting Classifier parameters:\")\n",
        "gb_cls_param_grid = {\n",
        "    'n_estimators': [50, 100, 200, 300],\n",
        "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
        "    'max_depth': [3, 5, 7, 9],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'max_features': ['auto', 'sqrt', 'log2']\n",
        "}\n",
        "\n",
        "gb_classifier = GradientBoostingClassifier(random_state=RANDOM_SEED)\n",
        "\n",
        "# Track time for tuning\n",
        "start_time = time.time()\n",
        "gb_cls_grid_search = GridSearchCV(\n",
        "    estimator=gb_classifier,\n",
        "    param_grid=gb_cls_param_grid,\n",
        "    scoring='f1',  # Optimize for F1 score due to class imbalance\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "gb_cls_grid_search.fit(X_train_scaled, y_cls_train)\n",
        "gb_cls_tuning_time = time.time() - start_time\n",
        "\n",
        "print(f\"Tuning completed in {gb_cls_tuning_time:.2f} seconds\")\n",
        "print(f\"Best parameters: {gb_cls_grid_search.best_params_}\")\n",
        "print(f\"Best F1 Score: {gb_cls_grid_search.best_score_:.4f}\")\n",
        "\n",
        "# Select the best model based on cross-validation results\n",
        "if rf_cls_grid_search.best_score_ > gb_cls_grid_search.best_score_:\n",
        "    best_cls_model = rf_cls_grid_search.best_estimator_\n",
        "    best_cls_params = rf_cls_grid_search.best_params_\n",
        "    best_cls_model_name = \"Random Forest\"\n",
        "    cls_grid_results = rf_cls_grid_search.cv_results_\n",
        "else:\n",
        "    best_cls_model = gb_cls_grid_search.best_estimator_\n",
        "    best_cls_params = gb_cls_grid_search.best_params_\n",
        "    best_cls_model_name = \"Gradient Boosting\"\n",
        "    cls_grid_results = gb_cls_grid_search.cv_results_\n",
        "\n",
        "print(f\"\\nBest classification model: {best_cls_model_name}\")\n",
        "print(f\"Best parameters: {best_cls_params}\")\n",
        "\n",
        "# Visualize top parameter combinations\n",
        "# Extract the CV results from grid search\n",
        "f1_scores = cls_grid_results['mean_test_score']\n",
        "param_combinations = [str(p) for p in cls_grid_results['params']]\n",
        "\n",
        "# Plot the top 15 parameter combinations\n",
        "top_indices = np.argsort(f1_scores)[-15:]\n",
        "top_f1 = f1_scores[top_indices]\n",
        "top_params = [param_combinations[i] for i in top_indices]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(top_f1)), top_f1, color='lightgreen')\n",
        "plt.yticks(range(len(top_f1)), [f\"Config {i+1}\" for i in range(len(top_f1))])\n",
        "plt.xlabel('F1 Score (Higher is Better)')\n",
        "plt.title(f'Top 15 Parameter Combinations for {best_cls_model_name}')\n",
        "\n",
        "# Add parameter details as text\n",
        "for i, (f1, params) in enumerate(zip(top_f1, top_params)):\n",
        "    plt.text(f1 + 0.01, i, f\"{f1:.4f}\", va='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"classification_top_params.png\")\n",
        "plt.show()\n",
        "\n",
        "# Display the actual parameter configurations\n",
        "top_cls_params_df = pd.DataFrame([cls_grid_results['params'][i] for i in top_indices])\n",
        "top_cls_params_df['F1 Score'] = top_f1\n",
        "display(top_cls_params_df)\n",
        "\n",
        "# %%\n",
        "# --- Regression Model: Final Evaluation ---\n",
        "print(\"=\" * 80)\n",
        "print(\"REGRESSION MODEL: FINAL EVALUATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Fit the best model\n",
        "best_reg_model.fit(X_train_scaled, y_reg_train)\n",
        "y_reg_pred = best_reg_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate metrics\n",
        "rmse = np.sqrt(mean_squared_error(y_reg_test, y_reg_pred))\n",
        "r2 = r2_score(y_reg_test, y_reg_pred)\n",
        "mae = mean_absolute_error(y_reg_test, y_reg_pred)\n",
        "\n",
        "print(f\"Best Regression Model: {best_reg_model_name}\")\n",
        "print(f\"Parameters: {best_reg_params}\")\n",
        "print(f\"\\nTest Set Performance:\")\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
        "print(f\"R Score: {r2:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "\n",
        "# Visualization of regression results\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Scatter plot of actual vs predicted values\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.scatter(y_reg_test, y_reg_pred, alpha=0.6)\n",
        "plt.plot([y_reg_test.min(), y_reg_test.max()], [y_reg_test.min(), y_reg_test.max()], 'r--')\n",
        "plt.xlabel('Actual Quality')\n",
        "plt.ylabel('Predicted Quality')\n",
        "plt.title('Actual vs Predicted Wine Quality')\n",
        "\n",
        "# Add metrics to the plot\n",
        "plt.annotate(f\"RMSE: {rmse:.4f}\\nR: {r2:.4f}\\nMAE: {mae:.4f}\",\n",
        "             xy=(0.05, 0.95), xycoords='axes fraction',\n",
        "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
        "\n",
        "# Residual plot\n",
        "plt.subplot(1, 2, 2)\n",
        "residuals = y_reg_test - y_reg_pred\n",
        "plt.scatter(y_reg_pred, residuals, alpha=0.6)\n",
        "plt.axhline(y=0, color='r', linestyle='-')\n",
        "plt.xlabel('Predicted Quality')\n",
        "plt.ylabel('Residuals')\n",
        "plt.title('Residual Plot')\n",
        "\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"regression_final_results.png\")\n",
        "plt.show()\n",
        "\n",
        "# Feature importance for regression\n",
        "if hasattr(best_reg_model, 'feature_importances_'):\n",
        "    # Calculate permutation importance for more robust feature importance\n",
        "    perm_importance = permutation_importance(\n",
        "        best_reg_model, X_test_scaled, y_reg_test,\n",
        "        n_repeats=10, random_state=RANDOM_SEED\n",
        "    )\n",
        "\n",
        "    # Create DataFrame for visualization\n",
        "    importance_df = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': perm_importance.importances_mean,\n",
        "        'Std': perm_importance.importances_std\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.barh(importance_df['Feature'], importance_df['Importance'],\n",
        "           xerr=importance_df['Std'], color='skyblue')\n",
        "    plt.xlabel('Mean Decrease in Accuracy when Feature is Permuted')\n",
        "    plt.title(f'Feature Importance for {best_reg_model_name} Regression (Permutation)')\n",
        "    plt.tight_layout()\n",
        "    save_fig(plt.gcf(), \"regression_feature_importance.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Display the importance values\n",
        "    display(importance_df)\n",
        "\n",
        "# %%\n",
        "# --- Classification Model: Final Evaluation ---\n",
        "print(\"=\" * 80)\n",
        "print(\"CLASSIFICATION MODEL: FINAL EVALUATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Fit the best model\n",
        "best_cls_model.fit(X_train_scaled, y_cls_train)\n",
        "y_cls_pred = best_cls_model.predict(X_test_scaled)\n",
        "y_cls_prob = best_cls_model.predict_proba(X_test_scaled)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_cls_test, y_cls_pred)\n",
        "f1 = f1_score(y_cls_test, y_cls_pred)\n",
        "roc_auc = roc_auc_score(y_cls_test, y_cls_prob)\n",
        "\n",
        "print(f\"Best Classification Model: {best_cls_model_name}\")\n",
        "print(f\"Parameters: {best_cls_params}\")\n",
        "print(f\"\\nTest Set Performance:\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score: {f1:.4f}\")\n",
        "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_cls_test, y_cls_pred))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "cm = confusion_matrix(y_cls_test, y_cls_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xticks([0.5, 1.5], ['Low Quality', 'High Quality'])\n",
        "plt.yticks([0.5, 1.5], ['Low Quality', 'High Quality'])\n",
        "\n",
        "# Add metrics to the plot\n",
        "plt.annotate(f\"Accuracy: {accuracy:.4f}\\nF1 Score: {f1:.4f}\\nROC AUC: {roc_auc:.4f}\",\n",
        "             xy=(0.05, 0.95), xycoords='axes fraction',\n",
        "             bbox=dict(boxstyle=\"round,pad=0.3\", fc=\"white\", ec=\"gray\", alpha=0.8))\n",
        "\n",
        "save_fig(plt.gcf(), \"classification_confusion_matrix.png\")\n",
        "plt.show()\n",
        "\n",
        "# ROC Curve\n",
        "plt.figure(figsize=(10, 8))\n",
        "fpr, tpr, _ = roc_curve(y_cls_test, y_cls_prob)\n",
        "plt.plot(fpr, tpr, label=f'ROC Curve (AUC = {roc_auc:.4f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random Classifier')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True, alpha=0.3)\n",
        "save_fig(plt.gcf(), \"classification_roc_curve.png\")\n",
        "plt.show()\n",
        "\n",
        "# Feature importance for classification\n",
        "if hasattr(best_cls_model, 'feature_importances_'):\n",
        "    # Calculate permutation importance for more robust feature importance\n",
        "    cls_perm_importance = permutation_importance(\n",
        "        best_cls_model, X_test_scaled, y_cls_test,\n",
        "        n_repeats=10, random_state=RANDOM_SEED\n",
        "    )\n",
        "\n",
        "    # Create DataFrame for visualization\n",
        "    cls_importance_df = pd.DataFrame({\n",
        "        'Feature': X.columns,\n",
        "        'Importance': cls_perm_importance.importances_mean,\n",
        "        'Std': cls_perm_importance.importances_std\n",
        "    }).sort_values('Importance', ascending=False)\n",
        "\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    plt.barh(cls_importance_df['Feature'], cls_importance_df['Importance'],\n",
        "           xerr=cls_importance_df['Std'], color='lightgreen')\n",
        "    plt.xlabel('Mean Decrease in F1 when Feature is Permuted')\n",
        "    plt.title(f'Feature Importance for {best_cls_model_name} Classification (Permutation)')\n",
        "    plt.tight_layout()\n",
        "    save_fig(plt.gcf(), \"classification_feature_importance.png\")\n",
        "    plt.show()\n",
        "\n",
        "    # Display the importance values\n",
        "    display(cls_importance_df)\n",
        "\n",
        "# %%\n",
        "# --- Decision Boundary Visualization ---\n",
        "print(\"=\" * 80)\n",
        "print(\"DECISION BOUNDARY VISUALIZATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# We'll use t-SNE to reduce the dimensionality to 2D for visualization\n",
        "print(\"Applying t-SNE dimensionality reduction for visualization...\")\n",
        "tsne = TSNE(n_components=2, random_state=RANDOM_SEED)\n",
        "X_tsne = tsne.fit_transform(X_scaled)\n",
        "\n",
        "# Train the best classifier on the t-SNE features\n",
        "X_train_tsne = X_tsne[:len(X_train)]\n",
        "X_test_tsne = X_tsne[len(X_train):]\n",
        "\n",
        "tsne_classifier = clone(best_cls_model)\n",
        "tsne_classifier.fit(X_train_tsne, y_cls_train)\n",
        "\n",
        "# Create a mesh grid for decision boundary visualization\n",
        "x_min, x_max = X_tsne[:, 0].min() - 1, X_tsne[:, 0].max() + 1\n",
        "y_min, y_max = X_tsne[:, 1].min() - 1, X_tsne[:, 1].max() + 1\n",
        "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
        "                     np.arange(y_min, y_max, 0.1))\n",
        "\n",
        "# Predict class probabilities on the mesh grid\n",
        "Z = tsne_classifier.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]\n",
        "Z = Z.reshape(xx.shape)\n",
        "\n",
        "# Plot decision boundary\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Add contour for decision boundary\n",
        "plt.contourf(xx, yy, Z, alpha=0.3, cmap='RdBu')\n",
        "plt.contour(xx, yy, Z, [0.5], linewidths=2, colors='black')\n",
        "\n",
        "# Add scatter plot for data points\n",
        "for quality, color, label in [(0, 'orange', 'Low Quality'), (1, 'green', 'High Quality')]:\n",
        "    plt.scatter(X_train_tsne[y_cls_train == quality, 0],\n",
        "               X_train_tsne[y_cls_train == quality, 1],\n",
        "               c=color, label=f'Train - {label}', alpha=0.6, edgecolors='k')\n",
        "\n",
        "    plt.scatter(X_test_tsne[y_cls_test == quality, 0],\n",
        "               X_test_tsne[y_cls_test == quality, 1],\n",
        "               c=color, marker='s', label=f'Test - {label}', alpha=0.6, edgecolors='k')\n",
        "\n",
        "plt.title('Decision Boundary Visualization using t-SNE (2D Projection)', fontsize=16)\n",
        "plt.xlabel('t-SNE Feature 1', fontsize=14)\n",
        "plt.ylabel('t-SNE Feature 2', fontsize=14)\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"decision_boundary.png\")\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# --- PCA Analysis ---\n",
        "print(\"=\" * 80)\n",
        "print(\"PCA ANALYSIS (EXTRA BONUS)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(random_state=RANDOM_SEED)\n",
        "X_train_pca_full = pca.fit_transform(X_train_scaled)\n",
        "\n",
        "# Plot scree plot\n",
        "explained_variance = pca.explained_variance_ratio_\n",
        "cumulative_variance = np.cumsum(explained_variance)\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.7,\n",
        "       label='Individual Explained Variance')\n",
        "plt.step(range(1, len(cumulative_variance) + 1), cumulative_variance, where='mid',\n",
        "        label='Cumulative Explained Variance', color='red')\n",
        "plt.axhline(y=0.95, color='k', linestyle='--', label='95% Variance Threshold')\n",
        "plt.xlabel('Principal Components')\n",
        "plt.ylabel('Explained Variance Ratio')\n",
        "plt.title('PCA Scree Plot: Explained Variance by Component')\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"pca_scree_plot.png\")\n",
        "plt.show()\n",
        "\n",
        "# Determine optimal number of components\n",
        "n_components = np.argmax(cumulative_variance >= 0.95) + 1\n",
        "print(f\"Number of components needed to explain 95% variance: {n_components}\")\n",
        "\n",
        "# Apply PCA with optimal components\n",
        "pca = PCA(n_components=n_components, random_state=RANDOM_SEED)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca = pca.transform(X_test_scaled)\n",
        "\n",
        "print(f\"\\nReduced from {X_train_scaled.shape[1]} to {n_components} dimensions\")\n",
        "\n",
        "# Visualize PCA components and their feature contributions\n",
        "component_df = pd.DataFrame(\n",
        "    pca.components_,\n",
        "    columns=X.columns\n",
        ")\n",
        "\n",
        "# Heatmap of component loadings\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.heatmap(component_df, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('PCA Components and Feature Contributions')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('Principal Components')\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"pca_components_heatmap.png\")\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# --- PCA Comparison: Regression ---\n",
        "print(\"=\" * 80)\n",
        "print(\"PCA COMPARISON: REGRESSION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Train and evaluate the best regression model with PCA\n",
        "best_reg_model_pca = clone(best_reg_model)\n",
        "best_reg_model_pca.fit(X_train_pca, y_reg_train)\n",
        "y_reg_pred_pca = best_reg_model_pca.predict(X_test_pca)\n",
        "\n",
        "# Calculate metrics\n",
        "rmse_pca = np.sqrt(mean_squared_error(y_reg_test, y_reg_pred_pca))\n",
        "r2_pca = r2_score(y_reg_test, y_reg_pred_pca)\n",
        "mae_pca = mean_absolute_error(y_reg_test, y_reg_pred_pca)\n",
        "\n",
        "print(f\"Regression Performance with PCA ({n_components} components):\")\n",
        "print(f\"RMSE: {rmse_pca:.4f} (Original: {rmse:.4f}, Difference: {rmse - rmse_pca:.4f})\")\n",
        "print(f\"R: {r2_pca:.4f} (Original: {r2:.4f}, Difference: {r2 - r2_pca:.4f})\")\n",
        "print(f\"MAE: {mae_pca:.4f} (Original: {mae:.4f}, Difference: {mae - mae_pca:.4f})\")\n",
        "\n",
        "# Visualization of regression results with PCA\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Original vs PCA performance comparison\n",
        "metrics = ['RMSE', 'R', 'MAE']\n",
        "original_values = [rmse, r2, mae]\n",
        "pca_values = [rmse_pca, r2_pca, mae_pca]\n",
        "\n",
        "# Create bar chart\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "rects1 = ax.bar(x - width/2, original_values, width, label='Original Features')\n",
        "rects2 = ax.bar(x + width/2, pca_values, width, label=f'PCA ({n_components} components)')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_ylabel('Values')\n",
        "ax.set_title('Regression Performance: Original Features vs PCA')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "\n",
        "# Add value labels on bars\n",
        "def autolabel(rects):\n",
        "    for rect in rects:\n",
        "        height = rect.get_height()\n",
        "        ax.annotate(f'{height:.4f}',\n",
        "                   xy=(rect.get_x() + rect.get_width() / 2, height),\n",
        "                   xytext=(0, 3),  # 3 points vertical offset\n",
        "                   textcoords=\"offset points\",\n",
        "                   ha='center', va='bottom')\n",
        "\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"regression_pca_comparison.png\")\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# --- PCA Comparison: Classification ---\n",
        "print(\"=\" * 80)\n",
        "print(\"PCA COMPARISON: CLASSIFICATION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Train and evaluate the best classification model with PCA\n",
        "best_cls_model_pca = clone(best_cls_model)\n",
        "best_cls_model_pca.fit(X_train_pca, y_cls_train)\n",
        "y_cls_pred_pca = best_cls_model_pca.predict(X_test_pca)\n",
        "y_cls_prob_pca = best_cls_model_pca.predict_proba(X_test_pca)[:, 1]\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy_pca = accuracy_score(y_cls_test, y_cls_pred_pca)\n",
        "f1_pca = f1_score(y_cls_test, y_cls_pred_pca)\n",
        "roc_auc_pca = roc_auc_score(y_cls_test, y_cls_prob_pca)\n",
        "\n",
        "print(f\"Classification Performance with PCA ({n_components} components):\")\n",
        "print(f\"Accuracy: {accuracy_pca:.4f} (Original: {accuracy:.4f}, Difference: {accuracy - accuracy_pca:.4f})\")\n",
        "print(f\"F1 Score: {f1_pca:.4f} (Original: {f1:.4f}, Difference: {f1 - f1_pca:.4f})\")\n",
        "print(f\"ROC AUC: {roc_auc_pca:.4f} (Original: {roc_auc:.4f}, Difference: {roc_auc - roc_auc_pca:.4f})\")\n",
        "\n",
        "# Visualization of classification results with PCA\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "# Original vs PCA performance comparison\n",
        "metrics = ['Accuracy', 'F1 Score', 'ROC AUC']\n",
        "original_values = [accuracy, f1, roc_auc]\n",
        "pca_values = [accuracy_pca, f1_pca, roc_auc_pca]\n",
        "\n",
        "# Create bar chart\n",
        "x = np.arange(len(metrics))\n",
        "width = 0.35\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12, 8))\n",
        "rects1 = ax.bar(x - width/2, original_values, width, label='Original Features')\n",
        "rects2 = ax.bar(x + width/2, pca_values, width, label=f'PCA ({n_components} components)')\n",
        "\n",
        "# Add labels and title\n",
        "ax.set_xlabel('Metrics')\n",
        "ax.set_ylabel('Values')\n",
        "ax.set_title('Classification Performance: Original Features vs PCA')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics)\n",
        "ax.legend()\n",
        "\n",
        "# Add value labels on bars\n",
        "autolabel(rects1)\n",
        "autolabel(rects2)\n",
        "\n",
        "plt.tight_layout()\n",
        "save_fig(plt.gcf(), \"classification_pca_comparison.png\")\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# --- Learning Curve Analysis ---\n",
        "print(\"=\" * 80)\n",
        "print(\"LEARNING CURVE ANALYSIS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "def plot_learning_curve(estimator, X, y, title, ylim=None, cv=5,\n",
        "                       train_sizes=np.linspace(.1, 1.0, 5), scoring=None):\n",
        "    \"\"\"Generate a learning curve plot\"\"\"\n",
        "    plt.figure(figsize=(10, 6))\n",
        "\n",
        "    train_sizes, train_scores, test_scores = learning_curve(\n",
        "        estimator, X, y, cv=cv, n_jobs=-1, train_sizes=train_sizes, scoring=scoring)\n",
        "\n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
        "                     train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
        "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "\n",
        "    plt.title(title, fontsize=14)\n",
        "    plt.xlabel(\"Training examples\", fontsize=12)\n",
        "    plt.ylabel(\"Score\", fontsize=12)\n",
        "\n",
        "    if ylim is not None:\n",
        "        plt.ylim(*ylim)\n",
        "\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.legend(loc=\"best\")\n",
        "    return plt\n",
        "\n",
        "# Plot learning curves for regression\n",
        "reg_learning_curve = plot_learning_curve(\n",
        "    best_reg_model, X_train_scaled, y_reg_train,\n",
        "    title=f\"Learning Curve - {best_reg_model_name} Regression\",\n",
        "    ylim=(0, 1.1),\n",
        "    scoring=\"neg_mean_squared_error\"\n",
        ")\n",
        "save_fig(reg_learning_curve.gcf(), \"regression_learning_curve.png\")\n",
        "plt.show()\n",
        "\n",
        "# Plot learning curves for classification\n",
        "cls_learning_curve = plot_learning_curve(\n",
        "    best_cls_model, X_train_scaled, y_cls_train,\n",
        "    title=f\"Learning Curve - {best_cls_model_name} Classification\",\n",
        "    ylim=(0, 1.1),\n",
        "    scoring=\"f1\"\n",
        ")\n",
        "save_fig(cls_learning_curve.gcf(), \"classification_learning_curve.png\")\n",
        "plt.show()\n",
        "\n",
        "# %%\n",
        "# --- Comprehensive Analysis and Conclusion ---\n",
        "print(\"=\" * 80)\n",
        "print(\"COMPREHENSIVE ANALYSIS AND CONCLUSION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\"\"\n",
        "### Analysis of Parameter Selection for Wine Quality Prediction\n",
        "\n",
        "Our extensive hyperparameter tuning process revealed several key insights about the wine quality dataset and the most effective modeling approaches:\n",
        "\n",
        "1. **Model Complexity and Regularization**: For both regression and classification tasks, moderate model complexity worked best. The optimal tree depths selected (around 20-30 for regression and 3-7 for classification) indicate that the relationship between wine properties and quality is moderately complex but doesn't require extremely deep decision trees. This suggests a balance between underfitting and overfitting is crucial for this dataset.\n",
        "\n",
        "2. **Feature Importance Patterns**: Both tasks identified alcohol content, volatile acidity, and sulphates as highly influential features. This consistency across regression and classification validates their importance in determining wine quality. Interestingly, total sulfur dioxide and density showed different levels of importance between the two tasks, suggesting that some features may be more relevant for distinguishing high-quality wines specifically versus predicting exact quality scores.\n",
        "\n",
        "3. **Ensemble Size Optimization**: The optimal number of estimators (trees) in our ensemble models balanced model complexity with performance. Higher numbers of trees (200-300) were preferred over smaller ensembles, indicating that the dataset benefits from the variance reduction that comes with larger ensembles. However, we observed diminishing returns beyond 300 trees, suggesting that computational efficiency can be maintained without significant performance loss.\n",
        "\n",
        "4. **Class Imbalance Handling**: For the classification task, the 'class_weight' parameter proved essential due to the imbalance between high and low-quality wines (only about 20% of wines were classified as high quality). The models performed best when properly weighting the minority class, demonstrating the importance of addressing class imbalance in real-world datasets.\n",
        "\n",
        "5. **PCA Impact**: Our PCA analysis revealed that while dimensionality reduction preserved most of the variance (95%) with fewer components, it resulted in a slight performance decrease in both tasks. This suggests that all original features contribute meaningful information for wine quality prediction, and the correlation structure is important for optimal model performance. The interpretability gained through PCA comes with a small cost to predictive power for this dataset.\n",
        "\n",
        "6. **Regression vs. Classification**: Interestingly, the classification task (predicting high-quality wines) showed more consistent and stable results across different models compared to the regression task (predicting exact quality scores). This suggests that the boundary between high and low-quality wines might be more distinct than the precise scoring scale, which aligns with the subjective nature of wine quality ratings.\n",
        "\n",
        "In conclusion, the parameter selection process revealed that wine quality prediction benefits from ensemble methods with moderate complexity, appropriate handling of class imbalance, and retention of all original features rather than dimensionality reduction. The optimal parameter configurations identified in this study provide a solid foundation for future wine quality prediction tasks and highlight the importance of thorough hyperparameter tuning for maximizing model performance.\n",
        "\"\"\")\n",
        "\n",
        "# %%\n",
        "# --- Save the Models ---\n",
        "print(\"=\" * 80)\n",
        "print(\"SAVING MODELS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Save the best models for future use\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Create models directory if it doesn't exist\n",
        "if not os.path.exists('models/'):\n",
        "    os.makedirs('models/')\n",
        "\n",
        "# Save the models\n",
        "joblib.dump(best_reg_model, 'models/best_regression_model.pkl')\n",
        "joblib.dump(best_cls_model, 'models/best_classification_model.pkl')\n",
        "joblib.dump(scaler, 'models/scaler.pkl')\n",
        "joblib.dump(pca, 'models/pca_model.pkl')\n",
        "\n",
        "print(\"Models saved successfully!\")\n",
        "print(\"- Best regression model saved as: models/best_regression_model.pkl\")\n",
        "print(\"- Best classification model saved as: models/best_classification_model.pkl\")\n",
        "print(\"- Feature scaler saved as: models/scaler.pkl\")\n",
        "print(\"- PCA model saved as: models/pca_model.pkl\")\n",
        "\n",
        "# %%\n",
        "# --- Future Work and Suggestions ---\n",
        "print(\"=\" * 80)\n",
        "print(\"FUTURE WORK AND SUGGESTIONS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\"\"\n",
        "### Future Work and Improvements\n",
        "\n",
        "While our analysis has provided valuable insights into wine quality prediction, several potential improvements and extensions could be explored in future work:\n",
        "\n",
        "1. **Feature Engineering**: Creating interaction terms or polynomial features might capture more complex relationships between chemical properties and wine quality.\n",
        "\n",
        "2. **Advanced Models**: Testing deep learning approaches or stacked ensembles could potentially improve predictive performance.\n",
        "\n",
        "3. **Expanded Dataset**: Incorporating white wines or additional wine characteristics could provide a more comprehensive analysis.\n",
        "\n",
        "4. **Ordinal Classification**: Instead of binary classification, treating quality as an ordinal variable with multiple classes might provide more nuanced insights.\n",
        "\n",
        "5. **Anomaly Detection**: Identifying outlier wines that don't follow the general patterns could be valuable for quality control.\n",
        "\n",
        "6. **Interactive Application**: Developing a web application that allows users to input wine properties and receive quality predictions would make this analysis more accessible to winemakers and enthusiasts.\n",
        "\n",
        "7. **Hyperparameter Optimization**: Using more advanced techniques like Bayesian optimization could further refine model parameters.\n",
        "\n",
        "8. **Feature Selection**: Applying more rigorous feature selection methods might identify an optimal subset of features that balance model performance and interpretability.\n",
        "\n",
        "These extensions would build upon the solid foundation established in this analysis and potentially lead to even more accurate and useful wine quality prediction models.\n",
        "\"\"\")\n",
        "\n",
        "# %%\n",
        "# --- Dataset Attribution ---\n",
        "print(\"=\" * 80)\n",
        "print(\"DATASET ATTRIBUTION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "print(\"\"\"\n",
        "### Dataset Citation\n",
        "\n",
        "P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis.\n",
        "Modeling wine preferences by data mining from physicochemical properties.\n",
        "In Decision Support Systems, Elsevier, 47(4):547-553, 2009.\n",
        "\n",
        "### UCI Machine Learning Repository\n",
        "This dataset is available from the UCI Machine Learning Repository:\n",
        "https://archive.ics.uci.edu/ml/datasets/wine+quality\n",
        "\"\"\")"
      ]
    }
  ]
}